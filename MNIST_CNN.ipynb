{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0qTyGKtPDpwen46IaNGlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjdgoruds2/AI-_assignment/blob/master/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRLtjDidVckY",
        "outputId": "81e9cae9-ace4-4f74-9994-2ec866222121"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist=fetch_openml('mnist_784',version=1,cache=True)\n",
        "\n",
        "X=mnist.data\n",
        "y=mnist.target\n",
        "\n",
        "import torch \n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=1/7,random_state=0)\n",
        "X_train=torch.Tensor(X_train)\n",
        "X_test=torch.Tensor(X_test)\n",
        "y_train=torch.LongTensor(list(map(int,y_train)))\n",
        "y_test=torch.LongTensor(list(map(int,y_test)))\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "X_train=X_train.view(-1,1,28,28).float()\n",
        "X_test=X_test.view(-1,1,28,28).float()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "train=TensorDataset(X_train,y_train)\n",
        "test=TensorDataset(X_test,y_test)\n",
        "BATCH_SIZE=32\n",
        "loader_train=DataLoader(train,batch_size=BATCH_SIZE,shuffle=False)\n",
        "loader_test=DataLoader(test,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,32,kernel_size=5)\n",
        "    self.conv2=nn.Conv2d(32,32,kernel_size=5)\n",
        "    self.conv3=nn.Conv2d(32,64,kernel_size=5)\n",
        "    self.fc1=nn.Linear(3*3*64,256)\n",
        "    self.fc2=nn.Linear(256,10)\n",
        "\n",
        "    self.loss_fn=nn.CrossEntropyLoss()\n",
        "    self.optimizer=optim.Adam(self.parameters(),lr=0.01)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=F.relu(F.max_pool2d(self.conv2(x),2))\n",
        "    x=F.dropout(x,p=0.5,training=self.training)\n",
        "    x=F.relu(F.max_pool2d(self.conv3(x),2))\n",
        "    x=F.dropout(x,p=0.5,training=self.training)\n",
        "    x=x.view(-1,3*3*64)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.dropout(x,training=self.training)\n",
        "    x=self.fc2(x)\n",
        "    return F.log_softmax(x,dim=1)\n",
        "\n",
        "def fit(model,loader_train):\n",
        "    optimizer=torch.optim.Adam(model.parameters())\n",
        "    error=nn.CrossEntropyLoss()\n",
        "    EPOCHS=1\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "      correct=0\n",
        "      for batch_idx,(X_batch,y_batch)in enumerate(loader_train):\n",
        "        var_X_batch=Variable(X_batch).float()\n",
        "        var_y_batch=Variable(y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        output=model(var_X_batch)\n",
        "        loss=error(output,var_y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        predicted=torch.max(output.data,1)[1]\n",
        "        correct+=(predicted==var_y_batch).sum()\n",
        "        if batch_idx %50==0:\n",
        "          print('에포크:{}[{}/{}({:.0f}%)]\\t 손실함수 :{:.6f}\\t Accuracy:{:.3f}%'.format(epoch,batch_idx*len(X_batch),len(loader_train),100.*batch_idx/len(loader_train),loss.data,correct*100./(BATCH_SIZE*(batch_idx+1))))\n",
        "def evaluate(model):\n",
        "  correct=0\n",
        "  for test_imgs,test_labels in loader_test:\n",
        "    test_imgs=Variable(test_imgs).float()\n",
        "    output=model(test_imgs)\n",
        "    predicted=torch.max(output,1)[1]\n",
        "    correct+=(predicted==test_labels).sum()\n",
        "  print(\"테스트 데이터 정확도:{:.3f}%\".format(float(correct)/(len(loader_test)*BATCH_SIZE)))\n",
        "cnn=CNN()\n",
        "evaluate(cnn)\n",
        "fit(cnn,loader_train)\n",
        "cnn.eval()\n",
        "evaluate(cnn)\n",
        "index=10\n",
        "data=X_test[index].view(-1,1,28,28).float()\n",
        "output=cnn(data)\n",
        "print('{}번째 학습데이터의 데스트 결과:{}'.format(index,output))\n",
        "_,predicted=torch.max(output,1)\n",
        "print('{}번째 데이터의 예측:{}'.format(index,predicted.numpy()))\n",
        "print('실제 레이블:{}'.format(y_test[index]))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n",
            "테스트 데이터 정확도:0.102%\n",
            "에포크:0[0/1875(0%)]\t 손실함수 :13.767502\t Accuracy:18.750%\n",
            "에포크:0[1600/1875(3%)]\t 손실함수 :1.951978\t Accuracy:17.586%\n",
            "에포크:0[3200/1875(5%)]\t 손실함수 :1.295147\t Accuracy:32.302%\n",
            "에포크:0[4800/1875(8%)]\t 손실함수 :0.809177\t Accuracy:43.564%\n",
            "에포크:0[6400/1875(11%)]\t 손실함수 :0.878456\t Accuracy:51.011%\n",
            "에포크:0[8000/1875(13%)]\t 손실함수 :0.735405\t Accuracy:56.238%\n",
            "에포크:0[9600/1875(16%)]\t 손실함수 :0.528978\t Accuracy:60.444%\n",
            "에포크:0[11200/1875(19%)]\t 손실함수 :0.359786\t Accuracy:63.746%\n",
            "에포크:0[12800/1875(21%)]\t 손실함수 :0.552548\t Accuracy:66.272%\n",
            "에포크:0[14400/1875(24%)]\t 손실함수 :0.337460\t Accuracy:68.376%\n",
            "에포크:0[16000/1875(27%)]\t 손실함수 :0.376636\t Accuracy:70.110%\n",
            "에포크:0[17600/1875(29%)]\t 손실함수 :0.566889\t Accuracy:71.523%\n",
            "에포크:0[19200/1875(32%)]\t 손실함수 :0.808957\t Accuracy:72.764%\n",
            "에포크:0[20800/1875(35%)]\t 손실함수 :0.317547\t Accuracy:73.867%\n",
            "에포크:0[22400/1875(37%)]\t 손실함수 :0.269136\t Accuracy:74.840%\n",
            "에포크:0[24000/1875(40%)]\t 손실함수 :0.276336\t Accuracy:75.737%\n",
            "에포크:0[25600/1875(43%)]\t 손실함수 :0.177124\t Accuracy:76.576%\n",
            "에포크:0[27200/1875(45%)]\t 손실함수 :0.523280\t Accuracy:77.457%\n",
            "에포크:0[28800/1875(48%)]\t 손실함수 :0.307685\t Accuracy:78.094%\n",
            "에포크:0[30400/1875(51%)]\t 손실함수 :0.169060\t Accuracy:78.815%\n",
            "에포크:0[32000/1875(53%)]\t 손실함수 :0.323939\t Accuracy:79.377%\n",
            "에포크:0[33600/1875(56%)]\t 손실함수 :0.235397\t Accuracy:79.930%\n",
            "에포크:0[35200/1875(59%)]\t 손실함수 :0.346146\t Accuracy:80.458%\n",
            "에포크:0[36800/1875(61%)]\t 손실함수 :0.494652\t Accuracy:80.913%\n",
            "에포크:0[38400/1875(64%)]\t 손실함수 :0.385411\t Accuracy:81.344%\n",
            "에포크:0[40000/1875(67%)]\t 손실함수 :0.150148\t Accuracy:81.817%\n",
            "에포크:0[41600/1875(69%)]\t 손실함수 :0.072488\t Accuracy:82.235%\n",
            "에포크:0[43200/1875(72%)]\t 손실함수 :0.084066\t Accuracy:82.617%\n",
            "에포크:0[44800/1875(75%)]\t 손실함수 :0.104306\t Accuracy:82.916%\n",
            "에포크:0[46400/1875(77%)]\t 손실함수 :0.193402\t Accuracy:83.234%\n",
            "에포크:0[48000/1875(80%)]\t 손실함수 :0.187650\t Accuracy:83.571%\n",
            "에포크:0[49600/1875(83%)]\t 손실함수 :0.268106\t Accuracy:83.847%\n",
            "에포크:0[51200/1875(85%)]\t 손실함수 :0.280481\t Accuracy:84.156%\n",
            "에포크:0[52800/1875(88%)]\t 손실함수 :0.070266\t Accuracy:84.419%\n",
            "에포크:0[54400/1875(91%)]\t 손실함수 :0.330519\t Accuracy:84.700%\n",
            "에포크:0[56000/1875(93%)]\t 손실함수 :0.324735\t Accuracy:84.962%\n",
            "에포크:0[57600/1875(96%)]\t 손실함수 :0.095551\t Accuracy:85.223%\n",
            "에포크:0[59200/1875(99%)]\t 손실함수 :0.175169\t Accuracy:85.467%\n",
            "테스트 데이터 정확도:0.968%\n",
            "10번째 학습데이터의 데스트 결과:tensor([[-9.1161e+00, -4.9853e-04, -9.2897e+00, -1.3297e+01, -8.9445e+00,\n",
            "         -1.1372e+01, -1.0481e+01, -1.1283e+01, -1.0118e+01, -9.5456e+00]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "10번째 데이터의 예측:[1]\n",
            "실제 레이블:1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}